{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41615240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp logs.services.cloud.datadog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6006002d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CloudHandler' from 'dc_logger.client.base' (/workspaces/dc_logger/dc_logger/client/base.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Any, Dict\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconcurrent\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfutures\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdc_logger\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CloudHandler\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# from ...client.models import LogEntry\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# from ...client.enums import LogLevel\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# from ...client.exceptions import LogHandlerError\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'CloudHandler' from 'dc_logger.client.base' (/workspaces/dc_logger/dc_logger/client/base.py)"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import socket\n",
    "import json\n",
    "from typing import List, Any, Dict\n",
    "import concurrent.futures\n",
    "\n",
    "from dc_logger.services.base import CloudHandler\n",
    "# from ...client.models import LogEntry\n",
    "# from ...client.enums import LogLevel\n",
    "# from ...client.exceptions import LogHandlerError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7484849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class DatadogHandler(CloudHandler):\n",
    "    \"\"\"Datadog log handler using direct HTTP API\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self._validate_config()\n",
    "\n",
    "    def _validate_config(self):\n",
    "        \"\"\"Validate Datadog configuration\"\"\"\n",
    "        api_key = self.cloud_config.get(\"api_key\")\n",
    "        if not api_key:\n",
    "            raise LogHandlerError(\"Datadog API key is required\")\n",
    "\n",
    "    def _get_hostname(self) -> str:\n",
    "        \"\"\"Get the actual hostname/IP address of the machine\"\"\"\n",
    "        try:\n",
    "            # Try to get the hostname, fallback to IP if needed\n",
    "            hostname = socket.gethostname()\n",
    "            # Get the IP address for more specific identification\n",
    "            ip_address = socket.gethostbyname(hostname)\n",
    "            return ip_address\n",
    "        except:\n",
    "            # Fallback to localhost if hostname resolution fails\n",
    "            return \"127.0.0.1\"\n",
    "\n",
    "    def _convert_log_level(self, level: LogLevel) -> str:\n",
    "        \"\"\"Convert LogLevel enum to Datadog log level\"\"\"\n",
    "        level_mapping = {\n",
    "            LogLevel.DEBUG: \"debug\",\n",
    "            LogLevel.INFO: \"info\",\n",
    "            LogLevel.WARNING: \"warning\",\n",
    "            LogLevel.ERROR: \"error\",\n",
    "            LogLevel.CRITICAL: \"critical\",\n",
    "        }\n",
    "        return level_mapping.get(level, \"info\")\n",
    "\n",
    "    def _safe_serialize(self, obj: Any) -> Any:\n",
    "        \"\"\"Safely serialize objects for JSON, handling complex types\"\"\"\n",
    "        if obj is None:\n",
    "            return None\n",
    "        \n",
    "        # Handle basic JSON-serializable types\n",
    "        if isinstance(obj, (str, int, float, bool)):\n",
    "            return obj\n",
    "        \n",
    "        # Handle lists\n",
    "        if isinstance(obj, list):\n",
    "            return [self._safe_serialize(item) for item in obj]\n",
    "        \n",
    "        # Handle dictionaries\n",
    "        if isinstance(obj, dict):\n",
    "            return {key: self._safe_serialize(value) for key, value in obj.items()}\n",
    "        \n",
    "        # Handle objects with to_dict method\n",
    "        if hasattr(obj, 'to_dict') and callable(getattr(obj, 'to_dict')):\n",
    "            try:\n",
    "                return self._safe_serialize(obj.to_dict())\n",
    "            except:\n",
    "                return str(obj)\n",
    "        \n",
    "        # Handle objects with __dict__\n",
    "        if hasattr(obj, '__dict__'):\n",
    "            try:\n",
    "                return self._safe_serialize(obj.__dict__)\n",
    "            except:\n",
    "                return str(obj)\n",
    "        \n",
    "        # Fallback to string representation, truncated for large objects\n",
    "        str_repr = str(obj)\n",
    "        if len(str_repr) > 1000:\n",
    "            return str_repr[:1000] + \"... (truncated)\"\n",
    "        return str_repr\n",
    "\n",
    "    def _send_logs_simple_api(self, entries: List[LogEntry]) -> bool:\n",
    "        \"\"\"Send logs using direct HTTP requests to Datadog\"\"\"\n",
    "        try:\n",
    "            import requests\n",
    "\n",
    "            # Get configuration\n",
    "            api_key = self.cloud_config.get(\"api_key\")\n",
    "            site = self.cloud_config.get(\"site\", \"datadoghq.com\")\n",
    "\n",
    "            # Determine the intake URL based on site\n",
    "            if site == \"datadoghq.com\":\n",
    "                intake_url = \"https://http-intake.logs.datadoghq.com/v1/input\"\n",
    "            elif site.startswith(\"us\"):\n",
    "                region = site.replace(\".datadoghq.com\", \"\")\n",
    "                intake_url = f\"https://http-intake.logs.{region}.datadoghq.com/v1/input\"\n",
    "            else:\n",
    "                intake_url = f\"https://http-intake.logs.{site}/v1/input\"\n",
    "\n",
    "            # Convert entries to log format\n",
    "            logs_data = []\n",
    "            hostname = self._get_hostname()\n",
    "            for entry in entries:\n",
    "                log_data = {\n",
    "                    \"message\": entry.message,\n",
    "                    \"ddsource\": \"domolibrary\",\n",
    "                    \"service\": self.cloud_config.get(\"service\", \"domolibrary\"),\n",
    "                    \"hostname\": hostname,\n",
    "                    \"status\": self._convert_log_level(entry.level),\n",
    "                    \"ddtags\": f\"env:{self.cloud_config.get('env', 'production')},service:{self.cloud_config.get('service', 'domolibrary')}\",\n",
    "                    \"timestamp\": entry.timestamp,\n",
    "                }\n",
    "\n",
    "                # Add structured data with safe serialization\n",
    "                if entry.entity:\n",
    "                    log_data[\"entity\"] = self._safe_serialize(entry.entity)\n",
    "\n",
    "                if entry.correlation:\n",
    "                    log_data[\"correlation\"] = {\n",
    "                        \"trace_id\": entry.correlation.trace_id,\n",
    "                        \"span_id\": entry.correlation.span_id,\n",
    "                        \"parent_span_id\": entry.correlation.parent_span_id,\n",
    "                    }\n",
    "\n",
    "                if entry.multi_tenant:\n",
    "                    log_data[\"multi_tenant\"] = {\n",
    "                        \"user_id\": entry.multi_tenant.user_id,\n",
    "                        \"session_id\": entry.multi_tenant.session_id,\n",
    "                        \"tenant_id\": entry.multi_tenant.tenant_id,\n",
    "                        \"organization_id\": entry.multi_tenant.organization_id,\n",
    "                    }\n",
    "\n",
    "                if entry.http_details:\n",
    "                    log_data[\"http_details\"] = {\n",
    "                        \"method\": entry.http_details.method,\n",
    "                        \"url\": entry.http_details.url,\n",
    "                        \"status_code\": entry.http_details.status_code,\n",
    "                        \"params\": self._safe_serialize(entry.http_details.params),\n",
    "                        \"request_body\": self._safe_serialize(entry.http_details.request_body),\n",
    "                        \"response_body\": entry.http_details.response_body if isinstance(entry.http_details.response_body, (str, int, float, bool, type(None))) else str(entry.http_details.response_body)[:500],\n",
    "                        \"response_size\": entry.http_details.response_size,\n",
    "                    }\n",
    "\n",
    "                if entry.extra:\n",
    "                    log_data[\"extra\"] = self._safe_serialize(entry.extra)\n",
    "\n",
    "                logs_data.append(log_data)\n",
    "\n",
    "            # Send via HTTP POST\n",
    "            headers = {\"Content-Type\": \"application/json\", \"DD-API-KEY\": api_key}\n",
    "\n",
    "            # Debug: Print first log entry for troubleshooting\n",
    "            if logs_data:\n",
    "                print(f\"DatadogHandler: Sending {len(logs_data)} log entries to {intake_url}\")\n",
    "                # Print a sample of the first log entry (truncated for readability)\n",
    "                sample_log = logs_data[0].copy()\n",
    "                if len(str(sample_log)) > 500:\n",
    "                    print(f\"DatadogHandler: Sample log entry: {str(sample_log)[:500]}...\")\n",
    "                else:\n",
    "                    print(f\"DatadogHandler: Sample log entry: {sample_log}\")\n",
    "\n",
    "            response = requests.post(\n",
    "                intake_url, json=logs_data, headers=headers, timeout=10\n",
    "            )\n",
    "\n",
    "            if response.status_code in [200, 202]:\n",
    "                print(f\"DatadogHandler: Successfully sent {len(logs_data)} log entries to Datadog\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\n",
    "                    f\"DatadogHandler: Failed to send logs - Status {response.status_code}: {response.text}\"\n",
    "                )\n",
    "                return False\n",
    "\n",
    "        except (TypeError, ValueError) as e:\n",
    "            print(f\"DatadogHandler: JSON serialization error - {e}\")\n",
    "            print(f\"DatadogHandler: Problematic data: {logs_data}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"DatadogHandler: Failed to send logs - {e}\")\n",
    "            return False\n",
    "\n",
    "    async def _send_to_cloud(self, entries: List[LogEntry]) -> bool:\n",
    "        \"\"\"Send log entries to Datadog using direct HTTP API\"\"\"\n",
    "\n",
    "        def submit_logs():\n",
    "            return self._send_logs_simple_api(entries)\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            future = executor.submit(submit_logs)\n",
    "            result = await asyncio.wrap_future(future)\n",
    "            return result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
